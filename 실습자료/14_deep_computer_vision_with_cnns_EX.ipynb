{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK7ecnb6pKzp"
      },
      "source": [
        "**Chapter 14 – Deep Computer Vision Using Convolutional Neural Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6cR-I1WpKzs"
      },
      "source": [
        "_This notebook contains all the sample code and solutions to the exercises in chapter 14._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFXIv9qNpKzt",
        "tags": []
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IPbJEmZpKzu"
      },
      "source": [
        "This project requires Python 3.7 or above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFSU3FCOpKzu"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "assert sys.version_info >= (3, 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAlKky09pKzv"
      },
      "source": [
        "It also requires Scikit-Learn ≥ 1.0.1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqCwW7cMpKzw"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import sklearn\n",
        "print(\"sklearn version: \", sklearn.__version__)\n",
        "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJtVEqxfpKzw"
      },
      "source": [
        "And TensorFlow ≥ 2.8:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Piq5se2pKzx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TF version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDaDoLQTpKzx"
      },
      "source": [
        "As we did in earlier chapters, let's define the default font sizes to make the figures prettier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d4TH3NbpKzx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTsawKlapKzy"
      },
      "source": [
        "This chapter can be very slow without a GPU, so let's make sure there's one, or else issue a warning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ekxzo6pOpKzy"
      },
      "outputs": [],
      "source": [
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. Neural nets can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware \"\n",
        "              \"accelerator.\")\n",
        "    if IS_KAGGLE:\n",
        "        print(\"Go to Settings > Accelerator and select GPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqMbn4NxaoHS"
      },
      "outputs": [],
      "source": [
        "# To prevent \"CUDNN_STATUS_ALLOC_FAILED\" error with GPUs\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oid44Xx-pKz6"
      },
      "source": [
        "# CNN Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELZe7PLfpKz6"
      },
      "source": [
        "**Tackling Fashion MNIST With a CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL6mFjsUaoHT"
      },
      "source": [
        "### Exercise 14.1\n",
        "- Construct simplified LeNet-5 as shown in the table\n",
        "- ReLu activation\n",
        "- Ignore S2->C3 connection and consider regular connection\n",
        "- Dropout rate: 0.5 for FC\n",
        "- Output layer: softmax\n",
        "- Train and evalute the LeNet-5 model and compare the results of the model in the practice code.\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK1AM86ZaoHT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# Define simplified LeNet-5\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model1 =\n",
        "\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_x17eKUjaoHU"
      },
      "outputs": [],
      "source": [
        "# Compile, train and evaluate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5L-wVUuaoHU"
      },
      "source": [
        "### Exercise 14.2\n",
        "Construct VGG-like LeNet for MNIST\n",
        "- 3 conv. Layers: each layer has 2 convolutional 3x3 filters with ReLU activation\n",
        "  -> in - c1 - c2 - s3 - c4 - c5 - s6 - c7 - c8 - fc - out\n",
        "- Number of kernels: 6-16-120\n",
        "- padding: SAME\n",
        "- Max pooling with 2x2 mask and stride=2\n",
        "- FC: 84-10.\n",
        "- Dropout rate: 0.5\n",
        "- Output: Softmax\n",
        "\n",
        "Compare results by changing # of kernels, # neurons of FC1, # of conv. layers, batch normalization, and activation functions.\n",
        "\n",
        "- Compare results with LeNet: Accuracy, Training time\n",
        "\n",
        "2. Kernal수를 아래와 변경하여 학습후 결과를 비교하시오.\n",
        "Number of kernels: 16-32-64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZUiK-wFaoHV"
      },
      "outputs": [],
      "source": [
        "# 14.2.1 Define VGG_like LeNet\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "\n",
        "model2 =\n",
        "\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEI90pAvaoHW"
      },
      "outputs": [],
      "source": [
        "# Compile, train and evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wQqUaZvaoHW"
      },
      "outputs": [],
      "source": [
        "# 14.2.2 Define VGG_like LeNet with different number of kernels\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model3 =\n",
        "\n",
        "model3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLvXCySuaoHW"
      },
      "outputs": [],
      "source": [
        "# Compile, train and evaluate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV10vudGpKz7"
      },
      "source": [
        "# Implementing a ResNet-34 CNN Using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I6CaSZLaoHX"
      },
      "source": [
        "### Exercise 14.3  \n",
        "Resen-34를 이용하여 Fashion MNIST를 학습시키고자 한다.  그러나 ReseNet-34는 ImageNet data aize인 224x224에 맞게 구성되어 있으므로 이를 수정하여야 한다.\n",
        "1. ResNet-34에 28x28의 Fashion MNSIT data를 입력할 경우 featue size의 변화를 확인하시오.\n",
        "2. Fashion MNIST data의 경우 크기가 작으므로 첫번째 conv. layer에서 feature size를 줄이는 것은 적합하지 않다. ResNet-34를 수정하여 첫번째 conv. layer에서 feature size를 유지하도록 하고 학습시킨 결과를 확인하고 LeNet-5 및 VGG-like LeNet과 비교하시오.\n",
        "3. ImageNet을 위한 ResNet-34는 7x7 feature를 GlobalAveragePooling layer를 통과시켰다. Fashion MNIST에 대해서도 동일한 동작을 하도록 high layer를 제거하고 학습결과를 비교하시오. Kernel 수는 low layer로부터 시작한 값을 유지한다.  \n",
        "(Layer수가 줄었으므로 ResNet-34는 적합하지 않고 ResNet-16이 적합하나 편의상 ResNet-34로 부르기로 한다)\n",
        "4. 3번에서 kernel수가 64, 128일 때 residual layer를 각각 3, 4개씩 유지하였는데 이를 2, 3개로 줄이고 학습결과를 비교하시오.\n",
        "5. 2-4번의 결과를 보고 accuracy를 유지하는 범위내에서 네트워크 복잡도를 줄여 학습시간을 최소화하는 ResNet-34를 설계하고 학습결과를 비교하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYBkzauaaoHX"
      },
      "outputs": [],
      "source": [
        "# Ex. 14.3.1\n",
        "# Define ResNet-34 for 28x28 input\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model4a ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQtaXbFaaoHY"
      },
      "outputs": [],
      "source": [
        "# Ex. 14.3.2\n",
        "# Modify ResNet-34\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model4b ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYMNPhBLaoHY"
      },
      "outputs": [],
      "source": [
        "# Compile, train and evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3I1VcGJaoHY"
      },
      "outputs": [],
      "source": [
        "# Ex. 14.3.3\n",
        "# Modify ResNet-34\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model4c ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EXVCatbaoHY"
      },
      "outputs": [],
      "source": [
        "# Compile, train and evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZPMOfm1aoHZ"
      },
      "outputs": [],
      "source": [
        "# Ex. 14.3.4\n",
        "# Modify ResNet-34\n",
        "\n",
        "model4d ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eZr5DppaoHZ"
      },
      "outputs": [],
      "source": [
        "# Compile, train and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_VVF9hBaoHZ"
      },
      "outputs": [],
      "source": [
        "# Ex. 14.3.5\n",
        "# Modify ResNet-34\n",
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "model4e ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l02WUzLAaoHZ"
      },
      "outputs": [],
      "source": [
        "# Compile, train and evaluate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqxnSBJ3pKz8"
      },
      "source": [
        "# Pretrained Models for Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB5EIFRsaoHa"
      },
      "source": [
        "### Exercise 14.4   \n",
        "1. 위의 셀들을 참조하여 base_model을 MobileNet으로 변경하여 학습시키시오.  \n",
        "2. Xception과 학습시간 및 정확도를 비교하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "oE8YQucvaoHa"
      },
      "outputs": [],
      "source": [
        "#14.4.1\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
        "\n",
        "model7 ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsyU2wLWaoHv"
      },
      "outputs": [],
      "source": [
        "# Compile and train top dense layer only\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX3HHaUlaoHv"
      },
      "outputs": [],
      "source": [
        "# Compile and train all layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIrP3W2GaoHw"
      },
      "source": [
        "#### 14.4.2  비교결과  \n",
        "1.  Xception 결과\n",
        "2.  Mobilenet 결과"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl9zizRopK0C"
      },
      "source": [
        "### Exercise 14.6\n",
        "_Exercise: Go through TensorFlow's [Style Transfer tutorial](https://homl.info/styletuto). It is a fun way to generate art using Deep Learning._  \n",
        "위의 tutorial 코드를 노트북에서 실행하여 결과를 제출."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}